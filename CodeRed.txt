Backend: (Cancelled for now)
    -Node.js
    -Firebase
    -MongoDB
UI:
    -Idea for updating tasks
    -1st logo screen (like supercell, nintendo)
    -opening Screen (the screen which is default and opens after the logo)
    -Tasks done screen (will take tasks done for that day)
    -other screens for inventory, stats, friends  etc
Grpahics:
    (if not mentioned make normal 2d)
    -seeds 
    -plants (done)
    -water droplets 
    -isometric grass blocks (done)
Game System:
    -rewards system of player on doing tasks ()
    -daily login rewards?
    -garden rendering
    -making the basic garden system (seeding, plantation, watering etc)
    -plant system

Grid dimensions:
X -> 142
Y -> 80

Verification of walking/cycling: (can be done in unity itself)
    - 1. Unity Setup
        Install Unity Input System Package to manage input from sensors.
        Use Unity's Input.location for GPS data and Input.acceleration for motion sensor data.
    - 2. Code:-
using UnityEngine;
using UnityEngine.UI;
using System.Collections;

public class ActivityTracker : MonoBehaviour
{
    // UI Elements
    public Text statusText;          // Displays GPS status
    public Text activityText;        // Displays activity type (Walking/Cycling)
    public Text distanceText;        // Displays total distance traveled

    private Vector2 startPosition;   // GPS starting position
    private Vector2 currentPosition; // GPS current position
    private bool tracking = false;   // GPS tracking status
    private float totalDistance = 0; // Total distance traveled in meters

    void Start()
    {
        StartCoroutine(StartGPS());  // Initialize GPS
    }

    IEnumerator StartGPS()
    {
        if (!Input.location.isEnabledByUser)
        {
            statusText.text = "GPS not enabled. Please enable location services.";
            yield break;
        }

        Input.location.Start(); // Start the GPS service

        // Wait until GPS initializes
        int maxWait = 20;
        while (Input.location.status == LocationServiceStatus.Initializing && maxWait > 0)
        {
            yield return new WaitForSeconds(1);
            maxWait--;
        }

        if (Input.location.status == LocationServiceStatus.Failed)
        {
            statusText.text = "Unable to determine device location.";
            yield break;
        }
        else
        {
            statusText.text = "GPS activated!";
            startPosition = new Vector2(Input.location.lastData.latitude, Input.location.lastData.longitude);
            tracking = true; // Start tracking
        }
    }

    void Update()
    {
        if (tracking)
        {
            TrackActivity(); // Detect activity type using motion sensors
            TrackDistance(); // Calculate distance using GPS
        }
    }

    void TrackActivity()
    {
        // Get accelerometer data
        Vector3 acceleration = Input.acceleration;

        // Detect walking or cycling based on motion patterns
        if (acceleration.magnitude > 0.3f && acceleration.magnitude < 1.5f)
        {
            activityText.text = "Walking Detected!";
        }
        else if (acceleration.magnitude >= 1.5f)
        {
            activityText.text = "Cycling Detected!";
        }
        else
        {
            activityText.text = "Stationary";
        }
    }

    void TrackDistance()
    {
        // Update the current GPS position
        currentPosition = new Vector2(Input.location.lastData.latitude, Input.location.lastData.longitude);

        // Calculate distance traveled since the last frame
        float distance = CalculateDistance(startPosition, currentPosition);

        // Update the total distance
        totalDistance += distance;

        // Display the total distance
        distanceText.text = "Distance: " + totalDistance.ToString("F2") + " meters";

        // Update the start position for the next frame
        startPosition = currentPosition;
    }

    float CalculateDistance(Vector2 start, Vector2 end)
    {
        float R = 6371e3f; // Radius of the Earth in meters
        float lat1 = start.x * Mathf.Deg2Rad;
        float lat2 = end.x * Mathf.Deg2Rad;
        float deltaLat = (end.x - start.x) * Mathf.Deg2Rad;
        float deltaLon = (end.y - start.y) * Mathf.Deg2Rad;

        float a = Mathf.Sin(deltaLat / 2) * Mathf.Sin(deltaLat / 2) +
                  Mathf.Cos(lat1) * Mathf.Cos(lat2) *
                  Mathf.Sin(deltaLon / 2) * Mathf.Sin(deltaLon / 2);

        float c = 2 * Mathf.Atan2(Mathf.Sqrt(a), Mathf.Sqrt(1 - a));
        float distance = R * c; // Distance in meters
        return distance;
    }

    void OnDestroy()
    {
        Input.location.Stop(); // Stop the GPS service when the app is closed
    }
}
    - 3. UI Setup in Unity
        Create a Canvas:

        Add three Text UI elements to your scene for:
        statusText: Displays the GPS status (e.g., "GPS activated").
        activityText: Displays the activity type (e.g., "Walking Detected").
        distanceText: Displays the total distance traveled.

        Assign References:
        Drag and drop the Text elements into their corresponding public fields in the ActivityTracker script in the Unity Inspector.

Add the following permissions to your AndroidManifest.xml file:
<uses-permission android:name="android.permission.ACCESS_FINE_LOCATION" />
<uses-permission android:name="android.permission.ACCESS_COARSE_LOCATION" />
<uses-permission android:name="android.permission.INTERNET" />

Integrating AI model with Unity:
    - C# code:-
using System.Collections;
using UnityEngine;
using TensorFlowLite;

public class ImageClassifier : MonoBehaviour
{
    [SerializeField] private TextAsset modelFile;  // Drag your .tflite file here
    private Interpreter interpreter;
    private WebCamTexture webCamTexture;

    private float[,] input;  // Input tensor (adjust based on your model's input shape)
    private float[] output;  // Output tensor (adjust based on your model's output shape)

    void Start()
    {
        // Initialize the TensorFlow Lite interpreter
        interpreter = new Interpreter(modelFile.bytes);
        interpreter.AllocateTensors();

        // Allocate input and output tensors based on model shape
        input = new float[1, 128, 128, 3]; // Example input size (128x128 RGB image)
        output = new float[1];             // Example output size (single classification score)

        // Start the camera
        StartCamera();
    }

    void Update()
    {
        if (webCamTexture != null && webCamTexture.isPlaying && webCamTexture.didUpdateThisFrame)
        {
            // Perform inference on the latest camera frame
            Texture2D cameraFrame = GetCameraFrame();
            ProcessImage(cameraFrame);

            interpreter.SetInputTensorData(0, input);
            interpreter.Invoke();
            interpreter.GetOutputTensorData(0, output);

            Debug.Log($"Prediction: {output[0]}");
        }
    }

    private void StartCamera()
    {
        // Use the default camera
        webCamTexture = new WebCamTexture();
        webCamTexture.Play();
    }

    private Texture2D GetCameraFrame()
    {
        // Create a Texture2D from the camera feed
        Texture2D frame = new Texture2D(webCamTexture.width, webCamTexture.height);
        frame.SetPixels32(webCamTexture.GetPixels32());
        frame.Apply();

        // Resize the image to match the model input size
        return ResizeTexture(frame, 128, 128);
    }

    private Texture2D ResizeTexture(Texture2D original, int width, int height)
    {
        RenderTexture rt = RenderTexture.GetTemporary(width, height);
        RenderTexture.active = rt;
        Graphics.Blit(original, rt);

        Texture2D resized = new Texture2D(width, height);
        resized.ReadPixels(new Rect(0, 0, width, height), 0, 0);
        resized.Apply();

        RenderTexture.active = null;
        RenderTexture.ReleaseTemporary(rt);

        return resized;
    }

    private void ProcessImage(Texture2D image)
    {
        Color32[] pixels = image.GetPixels32();
        for (int i = 0; i < pixels.Length; i++)
        {
            int y = i / image.width;
            int x = i % image.width;
            input[0, y, x, 0] = pixels[i].r / 255f;  // Normalize to [0, 1]
            input[0, y, x, 1] = pixels[i].g / 255f;
            input[0, y, x, 2] = pixels[i].b / 255f;
        }
    }

    private void OnDestroy()
    {
        webCamTexture?.Stop();
        webCamTexture = null;
        interpreter?.Dispose();
    }
}
